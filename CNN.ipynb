{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP3slWJfg5SKuj3khu5zTFY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/purnimapatel/Comparing-of-Deep_learning-Neural-Network/blob/main/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8xQjklfkQpU"
      },
      "source": [
        "#import the libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Dropout\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SRjlM85EVV2",
        "outputId": "3a0c4fbd-889e-443b-c414-4951053c40d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#opening the zip-file\n",
        "from zipfile import ZipFile\n",
        "file_name=\"UCI HAR Dataset.zip\"\n",
        "with ZipFile(file_name,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"DONE\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asgmbPmFEtNF"
      },
      "source": [
        "#those are separate normalised input features for the neural network\n",
        "SIGNALS = [\n",
        "    \"body_acc_x\",\n",
        "    \"body_acc_y\",\n",
        "    \"body_acc_z\",\n",
        "    \"body_gyro_x\",\n",
        "    \"body_gyro_y\",\n",
        "    \"body_gyro_z\",\n",
        "    \"total_acc_x\",\n",
        "    \"total_acc_y\",\n",
        "    \"total_acc_z\"\n",
        "]\n",
        "# Output classes to learn how to classify\n",
        "LABELS = [\n",
        "    \"WALKING\",\n",
        "    \"WALKING_UPSTAIRS\",\n",
        "    \"WALKING_DOWNSTAIRS\",\n",
        "    \"SITTING\",\n",
        "    \"STANDING\",\n",
        "    \"LAYING\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIeech3DEuaM"
      },
      "source": [
        "# Utility function to read the data from csv file\n",
        "def _read_csv(filename):\n",
        "    return pd.read_csv(filename, delim_whitespace=True, header=None)\n",
        "\n",
        "# Utility function to load the load_signals\n",
        "def load_signals(subset):\n",
        "    signals_data = []\n",
        "\n",
        "    for signal in SIGNALS:\n",
        "        filename = f'/content/UCI HAR Dataset/{subset}/Inertial Signals/{signal}_{subset}.txt'\n",
        "        #/content/UCI HAR Dataset/train/Inertial Signals\n",
        "        #/content/UCI HAR Dataset/train/Inertial Signals/body_acc_x_train.txt\n",
        "        signals_data.append(\n",
        "            _read_csv(filename).to_numpy()\n",
        "        ) \n",
        "\n",
        "    # Transpose is used to change the dimensionality of the output,\n",
        "    # aggregating the signals by combination of sample/timestep.\n",
        "    # Resultant shape is (7352 train/2947 test samples, 128 timesteps, 9 signals)\n",
        "    return np.transpose(signals_data, (1, 2, 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pc4lx4DOE1C_"
      },
      "source": [
        "def load_y(subset):\n",
        "    filename = f'/content/UCI HAR Dataset/{subset}/y_{subset}.txt'\n",
        "    y = _read_csv(filename)[0]\n",
        "\n",
        "    return pd.get_dummies(y).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zChTVcV7FAak"
      },
      "source": [
        "def load_data():\n",
        "    \"\"\"\n",
        "    Obtain the dataset from multiple files.\n",
        "    Returns: X_train, X_test, Y_train, Y_test\n",
        "    \"\"\"\n",
        "    X_train, X_test = load_signals('train'), load_signals('test')\n",
        "    Y_train, Y_test = load_y('train'), load_y('test')\n",
        "\n",
        "    return X_train, Y_train, X_test,  Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gajiuY_PJVrv"
      },
      "source": [
        "# Loading the train and test data\n",
        "X_train, Y_train, X_test,  Y_test = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dy4WII0cJIDN",
        "outputId": "5ec7e56c-2cde-4a32-af40-98b30d70bf7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7352, 128, 9)\n",
            "(7352, 6)\n",
            "(2947, 128, 9)\n",
            "(2947, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUdgHj3RFDzX"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "class scaling_tseries_data(BaseEstimator, TransformerMixin):\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    def __init__(self):\n",
        "        self.scale = None\n",
        "\n",
        "    def transform(self, X):\n",
        "        temp_X1 = X.reshape((X.shape[0] * X.shape[1], X.shape[2]))\n",
        "        temp_X1 = self.scale.transform(temp_X1)\n",
        "        return temp_X1.reshape(X.shape)\n",
        "\n",
        "    def fit(self, X):\n",
        "        # remove overlaping\n",
        "        remove = int(X.shape[1] / 2)\n",
        "        temp_X = X[:, -remove:, :]\n",
        "        # flatten data\n",
        "        temp_X = temp_X.reshape((temp_X.shape[0] * temp_X.shape[1], temp_X.shape[2]))\n",
        "        scale = StandardScaler()\n",
        "        scale.fit(temp_X)\n",
        "        self.scale = scale\n",
        "        return self"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qprVSQjFInCz"
      },
      "source": [
        "Scale = scaling_tseries_data()\n",
        "Scale.fit(X_train)\n",
        "X_train_sc = Scale.transform(X_train)\n",
        "X_test_sc = Scale.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMdLuvVuIoPs",
        "outputId": "e1865662-083b-4b6c-9672-7ef608be01c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Scaled_X_train',X_train_sc.shape)\n",
        "print('Scaled_X_test',X_test_sc.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Scaled_X_train (7352, 128, 9)\n",
            "Scaled_X_test (2947, 128, 9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC6vZCnTJ1HN"
      },
      "source": [
        "**Base_Model of CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yF-tBsHJ8Db",
        "outputId": "af1ab391-a793-472b-97cc-6bd2f9f65e7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform',input_shape=(128,9)))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, activation='relu',kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(6, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d (Conv1D)              (None, 126, 32)           896       \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 124, 32)           3104      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 124, 32)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 62, 32)            0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1984)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                99250     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 103,556\n",
            "Trainable params: 103,556\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q8rHAgoKFWM"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRcYI48pKLe-",
        "outputId": "b94d5437-f0cc-4450-9167-956db6892658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.fit(X_train_sc,Y_train, epochs=45, batch_size=16,validation_data=(X_test_sc, Y_test), verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.5256 - accuracy: 0.8203 - val_loss: 0.3470 - val_accuracy: 0.9019\n",
            "Epoch 2/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.1372 - accuracy: 0.9426 - val_loss: 0.3372 - val_accuracy: 0.8911\n",
            "Epoch 3/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.1119 - accuracy: 0.9523 - val_loss: 0.2824 - val_accuracy: 0.8979\n",
            "Epoch 4/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.1030 - accuracy: 0.9539 - val_loss: 0.2734 - val_accuracy: 0.9046\n",
            "Epoch 5/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0967 - accuracy: 0.9606 - val_loss: 0.2534 - val_accuracy: 0.9087\n",
            "Epoch 6/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0875 - accuracy: 0.9604 - val_loss: 0.2662 - val_accuracy: 0.9111\n",
            "Epoch 7/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0917 - accuracy: 0.9614 - val_loss: 0.2618 - val_accuracy: 0.9152\n",
            "Epoch 8/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0798 - accuracy: 0.9667 - val_loss: 0.2167 - val_accuracy: 0.9250\n",
            "Epoch 9/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0693 - accuracy: 0.9690 - val_loss: 0.2344 - val_accuracy: 0.9213\n",
            "Epoch 10/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0699 - accuracy: 0.9674 - val_loss: 0.2944 - val_accuracy: 0.9077\n",
            "Epoch 11/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0695 - accuracy: 0.9708 - val_loss: 0.2805 - val_accuracy: 0.9243\n",
            "Epoch 12/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0654 - accuracy: 0.9712 - val_loss: 0.2707 - val_accuracy: 0.9145\n",
            "Epoch 13/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0708 - accuracy: 0.9698 - val_loss: 0.2842 - val_accuracy: 0.9104\n",
            "Epoch 14/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0610 - accuracy: 0.9732 - val_loss: 0.3745 - val_accuracy: 0.9162\n",
            "Epoch 15/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0598 - accuracy: 0.9727 - val_loss: 0.2992 - val_accuracy: 0.9189\n",
            "Epoch 16/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0532 - accuracy: 0.9757 - val_loss: 0.2956 - val_accuracy: 0.9175\n",
            "Epoch 17/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0470 - accuracy: 0.9784 - val_loss: 0.2930 - val_accuracy: 0.9091\n",
            "Epoch 18/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0479 - accuracy: 0.9777 - val_loss: 0.4159 - val_accuracy: 0.9189\n",
            "Epoch 19/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0572 - accuracy: 0.9773 - val_loss: 0.3061 - val_accuracy: 0.9355\n",
            "Epoch 20/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0513 - accuracy: 0.9789 - val_loss: 0.2475 - val_accuracy: 0.9260\n",
            "Epoch 21/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0538 - accuracy: 0.9786 - val_loss: 0.3269 - val_accuracy: 0.9226\n",
            "Epoch 22/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0454 - accuracy: 0.9810 - val_loss: 0.2866 - val_accuracy: 0.9321\n",
            "Epoch 23/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0358 - accuracy: 0.9845 - val_loss: 0.2905 - val_accuracy: 0.9315\n",
            "Epoch 24/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0364 - accuracy: 0.9842 - val_loss: 0.2948 - val_accuracy: 0.9304\n",
            "Epoch 25/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0361 - accuracy: 0.9845 - val_loss: 0.3652 - val_accuracy: 0.9226\n",
            "Epoch 26/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0378 - accuracy: 0.9837 - val_loss: 0.3298 - val_accuracy: 0.9257\n",
            "Epoch 27/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0308 - accuracy: 0.9864 - val_loss: 0.3056 - val_accuracy: 0.9325\n",
            "Epoch 28/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0350 - accuracy: 0.9852 - val_loss: 0.3508 - val_accuracy: 0.9216\n",
            "Epoch 29/30\n",
            "460/460 [==============================] - 4s 8ms/step - loss: 0.0425 - accuracy: 0.9841 - val_loss: 0.3669 - val_accuracy: 0.9182\n",
            "Epoch 30/30\n",
            "460/460 [==============================] - 4s 9ms/step - loss: 0.0338 - accuracy: 0.9857 - val_loss: 0.3887 - val_accuracy: 0.9155\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f54d4c6d828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QIYOJsUUK7bU"
      },
      "source": [
        "Y_pred = model.predict(X_test_sc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqHlFVZhLI6L"
      },
      "source": [
        "pred = np.argmax(Y_pred,axis = 1) \n",
        "Y_actual = np.argmax(Y_test,axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}